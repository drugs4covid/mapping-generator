{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install owlready2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import csv\n",
    "import mysql.connector\n",
    "import numpy as numpy\n",
    "import json\n",
    "from sqlite3 import Error\n",
    "from owlready2 import *\n",
    "from math import floor, ceil\n",
    "from Levenshtein import distance as lev\n",
    "from enum import Enum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection is established:database.db\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "table AGENCY already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37094/959811755.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#http://vocab.gtfs.org/gtfs.ttl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0msql_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_37094/959811755.py\u001b[0m in \u001b[0;36msql_table\u001b[0;34m(con)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msql_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Agencia.sql\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msql_as_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msql_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mcursorObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutescript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_as_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: table AGENCY already exists"
     ]
    }
   ],
   "source": [
    "dataname = 'database.db'\n",
    "memory = ':memory:'\n",
    "try:\n",
    "    con = sqlite3.connect(dataname)\n",
    "    print(\"Connection is established:\" + dataname)\n",
    "except Error:\n",
    "    print (Error)\n",
    "        \n",
    "def sql_table(con):\n",
    "    cursorObj = con.cursor()\n",
    "    sql_file = open(\"Agencia.sql\")\n",
    "    sql_as_string = sql_file.read()\n",
    "    cursorObj.executescript(sql_as_string)\n",
    "    con.commit()\n",
    "\n",
    "#http://vocab.gtfs.org/gtfs.ttl\n",
    "sql_table(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_database():\n",
    "    try:\n",
    "        connection = mysql.connector.connect(host='localhost',\n",
    "                                     user='root',\n",
    "                                     password='gtfs',\n",
    "                                     database='gtfs',\n",
    "                                     charset='utf8mb4')\n",
    "\n",
    "        if connection.is_connected():\n",
    "                db_Info = connection.get_server_info()\n",
    "                print(\"Connected to MySQL Server version \", db_Info)\n",
    "                cursor = connection.cursor()\n",
    "                cursor.execute(\"select database();\")\n",
    "                record = cursor.fetchone()\n",
    "                print(\"You're connected to database: \", record)\n",
    "            \n",
    "        return connection, cursor\n",
    "\n",
    "    except Error as e:\n",
    "        print(\"Error while connecting to MySQL\", e)\n",
    "    #finally:\n",
    "    #    if connection.is_connected():\n",
    "    #        cursor.close()\n",
    "    #        connection.close()\n",
    "    #        print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tables(connection, cursor):\n",
    "    cursor.execute(\"show tables;\")\n",
    "    myresult = cursor.fetchall()\n",
    "    return myresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cur = connection.cursor()\n",
    "#cur.execute(\"SELECT * FROM AGENCY\")\n",
    "#cur.fetchall()\n",
    "cur.execute('DROP DATABASE IF EXISTS prueba.db')\n",
    "df = pd.read_sql_query(\"SELECT * FROM AGENCY\",con)\n",
    "print(df.to_string())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('examples/datasets/sql/1/AGENCY.csv')\n",
    "print(df.to_string()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadOntology(onto):\n",
    "    my_world = World()\n",
    "    ontology = onto\n",
    "    onto = my_world.get_ontology(ontology).load()\n",
    "    return onto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://vocab.gtfs.org/terms#\n",
      "gtfs\n"
     ]
    }
   ],
   "source": [
    "print(onto.base_iri)\n",
    "print(onto.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ontology_classes():\n",
    "    try:\n",
    "        l = list(my_world.sparql(\"\"\"\n",
    "                   SELECT  DISTINCT ?x \n",
    "                   { ?x a rdfs:Class . }\n",
    "            \"\"\"))\n",
    "    except:\n",
    "        l = list(my_world.sparql(\"\"\"\n",
    "                   SELECT  DISTINCT ?x \n",
    "                   { ?x a owl:Class . }\n",
    "            \"\"\"))\n",
    "    class_list_names = []\n",
    "    pair_class_names = []\n",
    "    for elem in l:\n",
    "        terms = str(elem).split('.')\n",
    "        pair_class_names.append((re.sub(']', '',terms.pop()), elem))\n",
    "    return pair_class_names\n",
    "\n",
    "def get_class_properties(class_prefix):\n",
    "    try:\n",
    "        l = list(my_world.sparql(\"\"\"\n",
    "                   SELECT  DISTINCT ?p where\n",
    "                   { \"\"\" + class_prefix + \"\"\" ?p . }\n",
    "            \"\"\"))\n",
    "    except:\n",
    "        print(\"error\")\n",
    "    prp_list_names = []\n",
    "    pair_prp_names = []\n",
    "    for elem in l:\n",
    "        terms = str(elem).split('.')\n",
    "        pair_prp_names.append((re.sub(']', '',terms.pop()), elem))\n",
    "    return pair_prp_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MySQL Server version  8.0.26\n",
      "You're connected to database:  ('gtfs',)\n",
      "Total number of columns in table: AGENCY ('agency_id', 'agency_name', 'agency_url', 'agency_timezone', 'agency_lang', 'agency_phone', 'agency_fare_url')\n",
      "Total number of columns in table: CALENDAR ('service_id', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'start_date', 'end_date')\n",
      "Total number of columns in table: CALENDAR_DATES ('service_id', 'date', 'exception_type')\n",
      "Total number of columns in table: FEED_INFO ('feed_publisher_name', 'feed_publisher_url', 'feed_lang', 'feed_start_date', 'feed_end_date', 'feed_version')\n",
      "Total number of columns in table: FREQUENCIES ('trip_id', 'start_time', 'end_time', 'headway_secs', 'exact_times')\n",
      "Total number of columns in table: ROUTES ('route_id', 'agency_id', 'route_short_name', 'route_long_name', 'route_desc', 'route_type', 'route_url', 'route_color', 'route_text_color')\n",
      "Total number of columns in table: SHAPES ('shape_id', 'shape_pt_lat', 'shape_pt_lon', 'shape_pt_sequence', 'shape_dist_traveled')\n",
      "Total number of columns in table: STOPS ('stop_id', 'stop_code', 'stop_name', 'stop_desc', 'stop_lat', 'stop_lon', 'zone_id', 'stop_url', 'location_type', 'parent_station', 'stop_timezone', 'wheelchair_boarding')\n",
      "Total number of columns in table: STOP_TIMES ('trip_id', 'arrival_time', 'departure_time', 'stop_id', 'stop_sequence', 'stop_headsign', 'pickup_type', 'drop_off_type', 'shape_dist_traveled')\n",
      "Total number of columns in table: TRIPS ('route_id', 'service_id', 'trip_id', 'trip_headsign', 'trip_short_name', 'direction_id', 'block_id', 'shape_id', 'wheelchair_accessible')\n",
      "\n",
      "Reading  Ontology...\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'my_world' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37094/4020585776.py\u001b[0m in \u001b[0;36mget_ontology_classes\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         l = list(my_world.sparql(\"\"\"\n\u001b[0m\u001b[1;32m      4\u001b[0m                    \u001b[0mSELECT\u001b[0m  \u001b[0mDISTINCT\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m?\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_world' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37094/3909938881.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nReading  Ontology...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0moc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ontology_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#oprp = get_ontology_properties()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_37094/4020585776.py\u001b[0m in \u001b[0;36mget_ontology_classes\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m             \"\"\"))\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         l = list(my_world.sparql(\"\"\"\n\u001b[0m\u001b[1;32m      9\u001b[0m                    \u001b[0mSELECT\u001b[0m  \u001b[0mDISTINCT\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m?\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                    \u001b[0;34m{\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m?\u001b[0m\u001b[0mx\u001b[0m \u001b[0ma\u001b[0m \u001b[0mowl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mClass\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_world' is not defined"
     ]
    }
   ],
   "source": [
    "connection, cursor = connect_database()\n",
    "tables = get_tables(connection,cursor)\n",
    "\n",
    "for y in tables:\n",
    "        sql_select_Query = \"select * from \" + y[0]\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(sql_select_Query)\n",
    "        # get all records\n",
    "        records = cursor.fetchall()\n",
    "        print(\"Total number of columns in table: \" + y[0], cursor.column_names)\n",
    "    \n",
    "print(\"\\nReading  Ontology...\\n\")\n",
    "oc = get_ontology_classes()\n",
    "#oprp = get_ontology_properties()\n",
    "print(oc)\n",
    "#print (oprp)\n",
    "print(tables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37094/3579504875.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m#print(\"Puntuación: \" + str(string_distance('CalendarDates', 'CalendarDateRule')))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrespondenceClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tables' is not defined"
     ]
    }
   ],
   "source": [
    "def levenshteinDistanceDP(token1, token2):\n",
    "    distances = numpy.zeros((len(token1) + 1, len(token2) + 1))\n",
    "\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "    return distances[len(token1)][len(token2)]\n",
    "    \n",
    "#min(1, 1 - abs(t1-t2)/len(token1))\n",
    "\n",
    "def string_distance(str1, str2):\n",
    "    distances = numpy.zeros(len(str1))\n",
    "    streak = 0\n",
    "    for x in range(0, len(str1)):\n",
    "        for y in range(x, len(str2)):\n",
    "            char1 = str1[x].lower()\n",
    "            char2 = str2[y].lower()\n",
    "            if char1 == char2:\n",
    "                val = min(1, 1 - abs(x-y)/(max(len(str1), len(str2))))\n",
    "                #print(val)\n",
    "                if distances[x] < val:\n",
    "                    distances[x] = val + streak\n",
    "                if val == 1:\n",
    "                    streak += 0.1\n",
    "                    break\n",
    "    #print(distances)\n",
    "    return numpy.sum(distances)/(max(len(str1), len(str2)))\n",
    "\n",
    "def correspondenceClass(ontology, table):\n",
    "    dis = 10\n",
    "    term = \"\"\n",
    "    for x in ontology:\n",
    "        #print(x[0])\n",
    "        term1 = str(table[0]).replace('_', '').lower()\n",
    "        term2 = str(x[0]).replace('_', '').lower()\n",
    "        auxDis = levenshteinDistanceDP(term1, term2)\n",
    "        #print(auxDis)\n",
    "        if auxDis < dis:\n",
    "            dis = auxDis\n",
    "            term = x\n",
    "    return term\n",
    "#print(\"Puntuación: \" + str(string_distance('CalendarDates', 'CalendarDateRule')))\n",
    "for x in range(0, len(tables)):\n",
    "    print(tables[x])\n",
    "    print(correspondenceClass(oc, tables[x]))\n",
    "#print(tables[4][0])\n",
    "#print(oc[3][0])\n",
    "#for x in range(0, len(tables)):\n",
    "#    print(\"Puntuación: \" + tables[0][0].lower() + \" \" + oc[x][0].lower() + \" :\" + str(lev(tables[0][0].lower(), oc[x][0].lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MySQL Server version  8.0.26\n",
      "You're connected to database:  ('gtfs',)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'my_world' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37094/4020585776.py\u001b[0m in \u001b[0;36mget_ontology_classes\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         l = list(my_world.sparql(\"\"\"\n\u001b[0m\u001b[1;32m      4\u001b[0m                    \u001b[0mSELECT\u001b[0m  \u001b[0mDISTINCT\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m?\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_world' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37094/1694391880.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0monto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadOntology\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gtfs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0montologyClasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ontology_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mRML_Transformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'properties.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0montologyClasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_37094/4020585776.py\u001b[0m in \u001b[0;36mget_ontology_classes\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m             \"\"\"))\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         l = list(my_world.sparql(\"\"\"\n\u001b[0m\u001b[1;32m      9\u001b[0m                    \u001b[0mSELECT\u001b[0m  \u001b[0mDISTINCT\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m?\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                    \u001b[0;34m{\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m?\u001b[0m\u001b[0mx\u001b[0m \u001b[0ma\u001b[0m \u001b[0mowl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mClass\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_world' is not defined"
     ]
    }
   ],
   "source": [
    "def loadProperties(outputFile, propertiesFile):\n",
    "    with open('properties/' + propertiesFile) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        json_file.close()\n",
    "    return data\n",
    "\n",
    "def writeProperties(output, properties):\n",
    "    with open('outputs/' + output, 'w') as fw:\n",
    "        original_stdout = sys.stdout\n",
    "        sys.stdout = fw\n",
    "        for x in properties['list_prefixes']:\n",
    "            print('@prefix ' + x['prefix'] + \": \" + x['URI'])\n",
    "        print('@base ' + properties['base']['URI'])\n",
    "        sys.stdout = original_stdout\n",
    "        fw.close()\n",
    "#print(data['list_prefixes'])\n",
    "\n",
    "def LogicalSource(table, SQLversion):\n",
    "    level = 8\n",
    "    print (\" \"*level, \"rml:logicalSource [\")\n",
    "    print (\" \"*(2*level), \"rml:source: \" + '\"' + \"<#DB_source>\" + '\"')\n",
    "    print (\" \"*(2*level), \"rr:sqlVersion \" + '\"' + SQLversion + '\"')\n",
    "    print (\" \"*(2*level), \"rr:tableName: \" + '\"' + table[0] + '\"')\n",
    "    print (\" \"*level, \"];\")\n",
    "    \n",
    "def TripleMap(subject):\n",
    "    level = 8\n",
    "    print (\"<\" + subject[0] + \">\")\n",
    "    print (\" \"*level, \"a rr:TriplesMap;\")\n",
    "    #print (\"\\n\")\n",
    "    LogicalSource(subject, \"SQL2008\")\n",
    "    \n",
    "#def SubjectMap(ontologyClasses):\n",
    "    \n",
    "\n",
    "def deleteFileContent(file):\n",
    "    file = open(\"outputs/\" + file,\"r+\")\n",
    "    file.truncate(0)\n",
    "    file.close()\n",
    "#def RMLTable(oc, table):\n",
    "\n",
    "def RML_Transformation(output, properties, tables, ontologyClasses):\n",
    "    data = loadProperties(output, properties)\n",
    "    writeProperties(output, data)\n",
    "    with open('outputs/' + output, 'w') as fw:\n",
    "        original_stdout = sys.stdout\n",
    "        sys.stdout = fw\n",
    "        for x in tables:\n",
    "            TripleMap(x)\n",
    "        sys.stdout = original_stdout\n",
    "        fw.close()\n",
    "        \n",
    "connection, cursor = connect_database()\n",
    "tables = get_tables(connection,cursor)\n",
    "onto = loadOntology(\"gtfs\")\n",
    "ontologyClasses = get_ontology_classes()\n",
    "RML_Transformation('output.txt', 'properties.json', tables, ontologyClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
